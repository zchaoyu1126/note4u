---
title: 《K8S in Action》第四章笔记
categories: Cloud Native
cover: 'http://img.note4u.top/base/cnnotes_cover.jpg'
abbrlink: 90f3ebae
date: 2023-04-19 21:20:27
tags:
---

pod 中的 container 失败时，会怎样，会自动重启吗？？？？


在实际使用 K8S 进行部署时，一般不会直接创建 pod，而是使用 ReplicationController、Deployment 等资源实现对 pod 的创建与管理。

这些资源将自动监控 pod。

在本章中，你将了解 Kubernetes 如何检查容器是否仍然存在，如果不存在则重新启动容器。
你还将学到如何运行托管的pod，既可以无限期运行，也可以执行单个任务，然后终止运行。


## pod 探针

使用K8S的一个好处是，可以给K8S一个容器列表来由其保持容器在集群中的运行。可以通过让K8S创建pod资源，为其选择一个工作节点，并在该节点上运行该pod的容器来完成此操作。

如果其中一个容器终止？一个pod中的所有容器都终止？怎么办？

只要将pod调度到某个节点，该节点的kubelet就会运行 pod 的容器，从此只要该 pod 在，就会保持运行。

如果容器的主进程崩溃，Kubelet将会重启 容器 。

如果应用程序中有一个导致它每个一段时间就会崩溃的bug，k8s会自动重启应用程序。即使应用程序本身没有做任何特殊的事情，在k8s中运行也能获得自我修复的能力。

即使进程没有崩溃，有时应用程序也会停止正常工作。例如，具有内存泄漏的Java应用程序将开始抛出 OutOfMemoryErrors，但JVM进程会一直运行。

让应用程序向 K8S发出信号，告诉它运行异常，让其重启。--》一个崩溃的容器会自动重启，所以捕获错误，并在错误发生时推出进程。但这并不能解决所有问题。


你的应用因为无限循环或死锁而停止响应。为了确保应用程序在这种情况下可以重新启动，必须从外部检查应用程序的运行状况，而不是依赖应用的内部检测。

### 存活探针
K8S 可以通过存活探针（liveness probe）检查容器是否还在运行。
可以为pod中的每个容器单独指定存活探针。如果探测失败，K8S 将定期执行探针并重新启动容器。

- HTTP GET探针对容器的IP地址（你指定的端口和路径）执行HTTP GET请求。
- TCP 套接字探针尝试与容器指定端口建立 TCP 连接。
- Exec 探针在容器内执行任意命令，并检查命令的退出状态码。 如果状态码是0，则探测成功。

### 基于 HTTP GET 请求的存活探针

``` SHELL
kubectl create -f kubia-liveness.yaml
```

``` YAML
apiVersion: v1
kind: Pod
metadata:
  name: kubia-liveness-pod
spec:
  containers:
  - name: kubia-liveness-container
    image: luksa/kubia-unhealthy
    resources:
      limits:
        memory: "128Mi"
        cpu: "500m"
    ports:
      - containerPort: 8080
        protocol: TCP
    livenessProbe:
      httpGet:
        path: /
        port: 8080
```

![20230420170617](http://img.note4u.top/article/20230420170617.png)


kubectl logs kubia-liveness-pod --previous
Kubia server starting...
Received request from ::ffff:10.244.0.1
Received request from ::ffff:10.244.0.1
Received request from ::ffff:10.244.0.1
Received request from ::ffff:10.244.0.1
Received request from ::ffff:10.244.0.1
Received request from ::ffff:10.244.0.1
Received request from ::ffff:10.244.0.1
Received request from ::ffff:10.244.0.1

kubectl logs kubia-liveness-pod
Kubia server starting...
Received request from ::ffff:10.244.0.1
Received request from ::ffff:10.244.0.1
Received request from ::ffff:10.244.0.1



Name:             kubia-liveness-pod
Namespace:        default
Priority:         0
Service Account:  default
Node:             minikube/192.168.49.2
Start Time:       Thu, 20 Apr 2023 11:24:47 +0800
Labels:           <none>
Annotations:      <none>
Status:           Running
IP:               10.244.0.30
IPs:
  IP:  10.244.0.30
Containers:
  kubia-liveness-container:
    Container ID:   docker://dda81f77e9bf5526ab0e22f0b68f70bb5cc70c41dd4051c73e3c5ea9fb37ec27
    Image:          luksa/kubia-unhealthy
    Image ID:       docker-pullable://luksa/kubia-unhealthy@sha256:5c746a42612be61209417d913030d97555cff0b8225092908c57634ad7c235f7
    Port:           8080/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Thu, 20 Apr 2023 17:07:26 +0800
    Last State:     Terminated
      Reason:       Error
      Exit Code:    137
      Started:      Thu, 20 Apr 2023 17:05:30 +0800
      Finished:     Thu, 20 Apr 2023 17:07:20 +0800
    Ready:          True
    Restart Count:  34
    Limits:
      cpu:     500m
      memory:  128Mi
    Requests:
      cpu:        500m
      memory:     128Mi
    Liveness:     http-get http://:8080/ delay=0s timeout=1s period=10s #success=1 #failure=3
    Environment:  <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-pxfr6 (ro)
Conditions:
  Type              Status
  Initialized       True
  Ready             True
  ContainersReady   True
  PodScheduled      True
Volumes:
  kube-api-access-pxfr6:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   Guaranteed
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason          Age                      From     Message
  ----     ------          ----                     ----     -------
  Warning  Unhealthy       3h58m (x79 over 5h39m)   kubelet  Liveness probe failed: HTTP probe failed with statuscode: 500
  Normal   Pulling         3h48m (x30 over 5h43m)   kubelet  Pulling image "luksa/kubia-unhealthy"
  Warning  BackOff         3h43m (x308 over 5h27m)  kubelet  Back-off restarting failed container kubia-liveness-container in pod kubia-liveness-pod_default(985969a9-4bdf-49f4-9498-e1b064c97b11)
  Normal   SandboxChanged  5m41s                    kubelet  Pod sandbox changed, it will be killed and re-created.
  Normal   Pulled          5m7s                     kubelet  Successfully pulled image "luksa/kubia-unhealthy" in 10.91591173s (10.915936531s including waiting)
  Normal   Pulled          3m4s                     kubelet  Successfully pulled image "luksa/kubia-unhealthy" in 4.767803682s (4.767815982s including waiting)
  Normal   Killing         101s (x2 over 3m41s)     kubelet  Container kubia-liveness-container failed liveness probe, will be restarted
  Normal   Pulling         70s (x3 over 5m18s)      kubelet  Pulling image "luksa/kubia-unhealthy"
  Normal   Pulled          67s                      kubelet  Successfully pulled image "luksa/kubia-unhealthy" in 3.216375977s (3.216382977s including waiting)
  Normal   Created         66s (x3 over 5m4s)       kubelet  Created container kubia-liveness-container
  Normal   Started         65s (x3 over 5m2s)       kubelet  Started container kubia-liveness-container
  Warning  Unhealthy       1s (x8 over 4m1s)        kubelet  Liveness probe failed: HTTP probe failed with statuscode: 500


laststate:137  
表示该进程由外部信号终止，128+x, x是终止进程的信号编号。 x=9 SIGKILL
底部列出的事件显示了容器为什么终止，K8S发现容器不健康，所以终止并重新创建。
当容器被强行终止时，会创建一个全新的容器，而不是重启原来的容器。


Liveness:     http-get http://:8080/ delay=0s timeout=1s period=10s #success=1 #failure=3

delay=0s 部分显示在容器启动后立即开始探测。timeout仅设置为1秒，因此容器必须在1秒内进行响应，不然这次探测记作失败，
每10秒探测一次容器（period=10s)，并在探测连续三次失败（#failure=3)后重启容器

定义探针时，可以自定义这些附加参数。
livenessProbe:
  httpGet:
    path: /
    port: 8080
  initialDelaySeconds: 15

如果没有设置初始盐池，探针将在启动时立即开始探测容器，这通常会导致探测失败，因为应用程序还没来得及准备好开始接受请求。
如果失败次数超过阈值，那么在应用程序能够正确响应请求之前，容器就会重启。

很多场合都会看到这种情况，用户很困惑为什么他们的容器正在重启。但是如果使用 kubectl describe，他们会看到容器以退出码 137 或 143 结束，并告诉他们该pod是被迫终止的。
此外，pod 事件的列表将显示容器因 liveness 探测失败而被终止。如果你在pod启动时看到这种情况，那是因为未能适当设置 initialDelaySeconds

137=128+9
143=128+15(SIGTERM)

### 创建有效的存活探针
对于正在生产运行中的pod，一定要定义一个存活探针，如果没有探针的话，k8s无法知道你的应用是否还活着。只要进程还在运行，k8s会认为容器是健康的。

1 存活探针应该检查什么？？
简易的存活探针仅仅检查了服务器是否响应，虽然这看起来简单，但是这在大多数情况下已经足够。
为了更好地进行存活检查，需要将探针配置为请求特定的URL路径，例如 /health 并让应用从内部运行的所有重要组件执行状态检查，以确保它们都没有终止或停止响应。

请确保/health HTTP端点不需要认证，否则探测会一直失败，导致容器无限重启。

一定要检查应用程序的内部，而没有任何外部因素的影响。例如，当服务器无法连接到后端数据库时，前端web服务器的存活探针不应该返回失败。
如果问题的底层原因在数据库，重启web服务器并不会解决该问题。由于存活探测的原因，将反复重启容器直到数据库恢复。

2 保持探针轻量
存活探针不应该消耗太多的计算资源，并且运行不应该花太长时间。
默认情况下，探测器执行的频率相对较高，必须在一秒内执行完毕。
一个过重的探针会大大减慢服务器的运行时间。

限制容器可用的CPU时间，探针的CPU时间计入容器的CPU时间配额，因此重量级的存活探针，将减少主应用程序的可用CPU时间。

如果在容器中运行java应用程序，请确保使用HTTP GET存活探针，而不是启动全新JVM以获取存活信息的 Exec探针。任何基于JVM或类似的应用程序也是如此，因为它们的启动过程需要大量的计算资源。

3 无须在探针中实现重试循环

探针的失败阈值是可以配置的，并且通常在容器被终止之前探针必须失败多次。
但即使你将失败阈值设置为1， Kubernetes为了确认一次探测的失败，会尝试若干次。因此在探针中自己实现重试循环是浪费精力。

## ReplicationController
### 概念
ReplicationController 可以创建和管理一个 pod 的多个副本，并会持续监控管理的所有 pod，保证相应其与期望的数目相等。

{% note info flat %}
在下文描述中，将使用 rc 来代替 ReplicationController。
{% endnote %}

rc 主要由三个部分组成：
- 标签选择器：用于确定 rc 作用域中有哪些 pod
- 副本个数：指定应运行的 pod 数量
- pod 模板：用于创建新的 pod 副本

当 rc 创建完毕后，标签选择器、副本个数、pod模板都可以随时修改，但只有副本数目的变更会影响现有的 pod。更改标签选择器，会使得现有的 pod 脱离 rc 的管理范围。而修改 pod 模板，则会影响由 rc 新创建的 pod。具体内容将在后文的小节中，结合实例进行说明。


使用 rc 的好处：
- 确保一个 pod 或多个 pod 副本的持续运行
- 集群节点发生故障时，将为故障节点上运行的所有 pod 创建替代副本
- 能够轻松实现 pod 的（手动、自动）水平伸缩

### 创建 rc

``` yaml
apiVersion: v1
kind: ReplicationController
metadata:
  name: kubia
spec:
  replicas: 3
  template:
    metadata:
      name: kubia-pod
      labels:
        app: kubia
    spec:
      containers:
      - name: kubia-container
        image: zchaoyu1126/kubia
        resources:
          limits:
            memory: "128Mi"
            cpu: "500m"
        ports:
        - containerPort: 8080
          protocol: TCP
```
{% note warning flat %}
使用原文中的 yaml 配置，出现 ImagePullBackOff、ErrImagePull 等错误，加入 resources 等信息后成功运行。
此外，关于 pod、container 等名字，应该如何命名？
{% endnote %}

pod 模板中的 pod 标签必须和 rc 的标签选择器匹配，否则 rc 将无休止地创建新容器。因为启动新的 pod 不会使实际的副本数量接近期望的副本数量。为了防止出现这种状况，API 服务会校验 rc 的定义，不会接受错误配置。

{% note info flat %}
不指定标签选择器时，会自动根据 pod 模板中的标签进行自动配置，这样可以使 yaml 文件更简短。
{% endnote %}

``` shell
kubectl create -f kubia-rc.yaml
kubectl get pods --show-labels
```

![20230515214356](http://img.note4u.top/article/20230515214356.png)

### pod 删除 
删除由 rc 管理的 kubia-4kb6x，此时 rc 将通过创建一个新的替代 pod 来响应 pod 的删除操作。

``` shell
kubectl delete pod kubia-4kb6x
kubectl get pods --show-labels
```

![20230515214542](http://img.note4u.top/article/20230515214542.png)

![20230515214836](http://img.note4u.top/article/20230515214836.png)

{% note warning flat%}
这里的 ErrImagePull 是什么？ 后面再次获取 pod 列表，为什么又自己好了？
{% endnote %}

通过 `get` 查看 rc，从左到右的数字依次表示所需的、实际的、就绪的 pod 数目。有时实际的 pod 数目会大于所需的 pod 数，这是因为存在一些 pod 正处于删除等状态。使用 `describe` 可以获取更详细的信息。

``` shell
kubectl get rc kubia
kubectl describe rc kubia
```

![20230515214653](http://img.note4u.top/article/20230515214653.png)

![20230515215315](http://img.note4u.top/article/20230515215315.png)

### 节点下线

当一个节点在几分钟内无法访问时，rc 会将调度到该节点的 pod 状态将变为`Unkonwn`，并立即启动一个新的 pod 代替。当节点再次启动时，对应状态应该返回到 `Ready`，并且状态为 `Unkonwn` 的 pod 将被删除。

{% note warning flat %}
使用minikube 无法完成本实验，之后有条件时验证。
{% endnote %}

### 从 rc 的作用域中移除
由 rc 创建的 pod 并不是与 rc 绑定。在任何时刻，rc 管理与标签选择器匹配的 pod。更改 pod 的标签，可以将它从 rc 的作用域中添加或删除，甚至可以从一个移动到另一个。

``` shell
kubectl label pod kubia-manual-gpu app=kubia --overwrite
kubectl get pods --show-labels
kubectl label pod kubia-manual-gpu app=foo --overwrite
kubectl get pods --show-labels
```

![20230515220320](http://img.note4u.top/article/20230515220320.png)

![20230515220407](http://img.note4u.top/article/20230515220407.png)

尽管 pod 没有绑定到 rc,但在 pod 的 metadata.ownerReferences 字段中引用了 rc，可以轻松使用该字段来找到 pod 所属的 rc。

``` shell
kubectl get pod kubia-t9bpq -o yaml
```

![20230515220919](http://img.note4u.top/article/20230515220919.png)

### 修改标签选择器

如果修改 rc 的标签选择器，让所有的pod都脱离 rc 的控制，导致它创建三个新的pod。k8s 确实允许更改 rc 的标签选择器，但修改标签选择器的同时，必须修改 pod 模板。此外，这种做法不适用于本章后半部分中介绍的其他资源。

### 修改 pod 模板

rc 的 pod 模板可以随时修改，但不能对原有匹配的标签进行修改。否则，需要同时修改标签选择器。此时，会重新生成对应数目的 pod。

pod 模板修改完毕后，但不会影响现有的 pod。只有将旧的 pod 删除后，rc 才会根据新模板将其替换为新的pod。

![20230515093701](http://img.note4u.top/article/20230515093701.png)

找到pod模板部分并向元数据添加一个新的标签。然后再次列出 pod 及其标签，发现标签并未发生变化。但如果删除了某个 pod 后，并等待其替代 pod 创建，就会发现新的标签。

![20230515222441](http://img.note4u.top/article/20230515222441.png)

![20230515222620](http://img.note4u.top/article/20230515222620.png)

像这样首先编辑 rc ，来更改容器模板中的容器图像。其次，删除现有的容器，最后将它们替换为新模板中的新容器，可以用于升级 pod。但实际使用时，常使用 Deployment 完成。

可以设置 KUBE_EDITOR 环境变量来告诉 kubectl 使用期望的文本编辑器，否则使用默认文本编辑器。

### 修改副本数目

修改 spec.replicas 字段（副本数目），可以实现水平扩容或缩容。

``` shell
kubectl edit rc kubia
kubectl scale rc kubia --replicas=10
kubectl scale rc kubia --replicas=3
``` 

### 删除 rc

删除 rc 时，由其管理的 pod 也会被删除，可以使用 `--cascade=false` 来保留 pod。
如果不输入该参数，则默认为 `--cascade=true`。

``` shell
kubectl delete rc kubia --cascade=false
```

## ReplicaSet

replicaset 是新一代的 rc，rc最终将被弃用。


rc和rs几乎完全相同，但你通常不会直接创建它们，而是在创建更高层级的deployment资源时，自动创建它们。

区别：
rs行为完全相同，但pod选择器的表达能力更强。
虽然 rc 的标签选择器只允许包含某个标签的的匹配pod
但 rs 的选择器还允许匹配缺少某个标签的pod，或包含特定标签名的pod，不管其值如何
同样，无论 Replic tionC ntr ller 的值如何， Repl ication Controller 都无法仅基于
标签名的存在来匹配 pod ，而 Rep licaS et 则可以 例如， Rep lic aSet 可匹配所有包含
名为 env 标签的 pod 无论 ReplicaS et 的实际值是什么（可以理解为 env＝仆


创建一个名为 kubia-replicaset.yaml 的新文件，将你的Kind 从
replicationcontroller 修改为 replicaset



## DaemonSet

## Job、CronJob